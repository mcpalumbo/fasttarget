from ftscripts import programs, metadata
import os
import shutil
import sys
import re
import numpy
import pandas as pd
import networkx as nx
from networkx.algorithms.centrality.betweenness import betweenness_centrality
from networkx.algorithms.components.connected import connected_components

def process_sbml(base_path, organism_name, sbml_file):
    """
    Process the SBML file to generate the Ubiquitous Compounds file inside the metabolism directory.
    This function uses the `run_ubiquitous` function from the `programs` module.

    :param base_path: Base path where the repository data is stored.
    :param organism_name: Name of the organism.
    :param sbml_file: Path to the SBML file
    """
    
    metabolism_dir = os.path.join(base_path, 'organism', organism_name, 'metabolism')
    sbml_path = os.path.join(metabolism_dir, f'{organism_name}.sbml')

    if os.path.exists(sbml_file):
        shutil.copyfile(sbml_file, sbml_path)

        print(f'Processing {sbml_path}')

        programs.run_ubiquitous(sbml_path, metabolism_dir)

        print(f'List of Ubiquitous Compounds saved to {metabolism_dir}/ubiquitous_compounds.txt.')
 
    else:
        print(f"SBML file '{sbml_file}' not found.", file=sys.stderr)

def ubiquitous_checker(base_path, organism_name):
    """
    Check if the ubiquitous_compounds.txt file was renamed and moved to the metabolism directory.
    This function prompts the user to curate and rename the file and waits for the user to press Enter.    

    :param base_path: Base path where the repository data is stored.
    :param organism_name: Name of the organism.
    """

    metabolism_dir = os.path.join(base_path, 'organism', organism_name, 'metabolism')
    ubiquitous_file = os.path.join(metabolism_dir, f'{organism_name}_ubiquitous.txt')
    
    print(f'Please curate ubiquitous_compounds.txt and rename as {ubiquitous_file}')
    
    while True:
        input("Press Enter after renaming the file...")
        
        if os.path.exists(ubiquitous_file):
            print(f"File successfully renamed to {ubiquitous_file}. Proceeding with the pipeline...")
            break
        else:
            print(f"{ubiquitous_file} not found. Please rename the file or try again.")

def generate_sif(base_path, organism_name):
    """
    Generate the network.sif file from the SBML file and the Ubiquitous Compounds file.
    This function uses the `run_sbml_to_sif` function from the `programs` module.
    
    :param base_path: Base path where the repository data is stored.
    :param organism_name: Name of the organism.
    """

    metabolism_dir = os.path.join(base_path, 'organism', organism_name, 'metabolism')
    sbml_path = os.path.join(metabolism_dir, f'{organism_name}.sbml')
    ubiquitous_file = os.path.join(metabolism_dir, f'{organism_name}_ubiquitous.txt')

    programs.run_sbml_to_sif(sbml_path, ubiquitous_file, metabolism_dir)
    print(f'Sif file generated in {metabolism_dir}.')

def process_chokepoint_ptools(base_path, organism_name, chokepoint_file):
    """
    Process the chokepoint file generated by Pathway Tools.
    This function reads the chokepoint file, extracts the producing and consuming chokepoints, and returns the sets of reactions.
    
    :param base_path: Base path where the repository data is stored.
    :param organism_name: Name of the organism.
    :param chokepoint_file: Path to the chokepoint file.

    :return: Sets of producing chokepoints.
    :return: Sets of consuming chokepoints.
    :return: Sets of both producing and consuming chokepoints.
    """

    metabolism_dir = os.path.join(base_path, 'organism', organism_name, 'metabolism')
    chokepoint_path = os.path.join(metabolism_dir, f'{organism_name}_chokepoints.txt')

    if os.path.exists(chokepoint_file):
        shutil.copy(chokepoint_file, chokepoint_path)
    else:
        print(f"Chokepoint file '{chokepoint_file}' not found.", file=sys.stderr)

    with open(chokepoint_path, 'r') as file:
        text = file.read()

    # Define regular expressions for finding sections
    producing_pattern = r"Reactions that are chokepoints on the producing side \(\d+\):\n((?:.*\n)*)\nReactions that are chokepoints on the consuming side"
    consuming_pattern = r"Reactions that are chokepoints on the consuming side \(\d+\):\n((?:.*\n)*)\nReactions that are not chokepoints, but are candidates"

    # Extract the producing side reactions
    producing_match = re.search(producing_pattern, text)
    producing_reactions = producing_match.group(1).strip().split('\n') if producing_match else []

    # Extract the consuming side reactions
    consuming_match = re.search(consuming_pattern, text)
    consuming_reactions = consuming_match.group(1).strip().split('\n') if consuming_match else []

    producing_list = []
    for reaction in producing_reactions:
        producing_list.append(reaction.split('  ', 1)[0])
        
    consuming_list = []
    for reaction in consuming_reactions:
        consuming_list.append(reaction.split('  ', 1)[0])
    
    producing_set = set(producing_list)
    consuming_set = set(consuming_list)
    
    print('Total producing chokepoints')
    print(len(producing_set))
    print('Total consuming chokepoints')
    print(len(consuming_set))
    
    both_set = producing_set & consuming_set
    producing_only_set = producing_set - both_set
    consuming_only_set = consuming_set - both_set
    
    print('Only producing chokepoints')
    print(len(producing_only_set))
    print('Only consuming chokepoints')
    print(len(consuming_only_set))
    print('Both producing and consuming chokepoints')
    print(len(both_set))
    
    return producing_only_set, consuming_only_set, both_set

def process_genes_smarttable(base_path, organism_name, smarttable_file):
    """
    This function reads the Smarttable file, extracts the genes and their associated reactions, and returns a dictionary with the genes as keys and the reactions as values.
    
    :param base_path: Base path where the repository data is stored.
    :param organism_name: Name of the organism.
    :param smarttable_file: Path to the Smarttable file.
    
    :return: Dictionary with the genes as keys and the reactions as values.
    """

    metabolism_dir = os.path.join(base_path, 'organism', organism_name, 'metabolism')
    smarttable_path = os.path.join(metabolism_dir, f'{organism_name}_smarttable.txt')

    if os.path.exists(smarttable_file):
        shutil.copy(smarttable_file, smarttable_path)
    else:
        print(f"Smarttable file '{smarttable_file}' not found.", file=sys.stderr)

    df_genes = pd.read_csv(smarttable_path, delimiter='\t', usecols=['ID', 'Reactions'])
    df_genes = df_genes.dropna(subset=['Reactions'], how='all')
    reaction_dict = {row['ID']: [reaction.strip() for reaction in row['Reactions'].split(',')] for index, row in df_genes.iterrows()}

    return reaction_dict

def write_sif(graph, file_path):
    """
    Write a networkx graph to a SIF file.

    :param graph: Networkx graph.
    :param file_path: Path to the SIF file.
    """
    with open(file_path, 'w') as file:
        for edge in graph.edges():
            file.write(f"{edge[0]}\tinteracts\t{edge[1]}\n")

def read_sif(base_path, organism_name):
    """
    This function reads the network.sif file, generates the principal component of the network, and calculates the betweenness centrality and node degrees.

    :param base_path: Base path where the repository data is stored.
    :param organism_name: Name of the organism.

    :return: The complete network.
    :return: The principal component of the network.
    :return: Dictionary with the betweenness centrality values.
    :return: Dictionary with the node degrees.
    """

    metabolism_dir = os.path.join(base_path, 'organism', organism_name, 'metabolism')
    sif_path = os.path.join(metabolism_dir, 'network.sif')

    G = nx.DiGraph()
    with open(sif_path, 'r') as file:
        for line in file:
            parts = line.strip().split()
            if len(parts) == 3:
                source, interaction, target = parts
                G.add_edge(source, target, interaction=interaction)
                
    largest_component = max(nx.weakly_connected_components(G), key=len)
    subgraph = G.subgraph(largest_component).copy()
    write_sif(subgraph, os.path.join(metabolism_dir, f'{organism_name}_principal_component.sif'))
    
    betweenness_centrality = nx.betweenness_centrality(subgraph)
    max_value = max(value for value in betweenness_centrality.values())
    normalized_betweenness_centrality = {key: (value / max_value) for key, value in betweenness_centrality.items()} 

    node_degrees = dict(subgraph.degree())
    
    return G, subgraph, normalized_betweenness_centrality, node_degrees   

def mapping_metabolism(locus_reaction_dict, reaction_property_dict):
    """
    This function maps the betweenness centrality values to the genes.

    :param locus_reaction_dict: Dictionary with the genes as keys and the reactions as values.
    :param reaction_property_dict: Dictionary with the reactions as keys and the betweenness centrality values as values.

    :return: Dictionary with the genes as keys and the betweenness centrality values as values.
    """
    
    locustag_to_values = {}

    for gene, rxns in locus_reaction_dict.items():
        values = [reaction_property_dict[rxn] for rxn in rxns if rxn in reaction_property_dict]
        locustag_to_values[gene] = values
        
    locustag_max = {}
    for gene, values in locustag_to_values.items():
        if len(values)>0:
            locustag_max[gene] = max(values)
        else:
            locustag_max[gene] = 0   
    
    return locustag_max

def mapping_chokepoints(locus_reaction_dict, producing_ck, consuming_ck, both_ck):
    """
    This function maps the chokepoints to the genes.

    :param locus_reaction_dict: Dictionary with the genes as keys and the reactions as values.
    :param producing_ck: Set of producing chokepoints.
    :param consuming_ck: Set of consuming chokepoints.
    :param both_ck: Set of both producing and consuming chokepoints.

    :return: Dictionaries with the genes as keys and the chokepoints as values. Returns three dictionaries: producing chokepoints, consuming chokepoints, and both chokepoints.
    """
    
    producing_chokepoint = {}
    consuming_chokepoint = {}
    both_chokepoint = {}
        
    for gene, rxns in locus_reaction_dict.items():
        for rxn in rxns:
            if rxn in producing_ck:
                producing_chokepoint[gene] = rxn
            elif rxn in consuming_ck:
                consuming_chokepoint[gene] = rxn
            elif rxn in both_ck:
                both_chokepoint[gene] = rxn

    return producing_chokepoint, consuming_chokepoint, both_chokepoint

def run_metabolism (base_path, organism_name, sbml_file, chokepoint_file, smarttable_file):
    """
    Runs the metabolism pipeline. 
    It processes the SBML file, generates the Ubiquitous Compounds file, the network SIF file, and the gene-reaction mapping. 
    Returns DataFrames with locus_tag as key and the values of betweenness centrality, node degrees, and chokepoints.
    The DataFrames are created using the functions `metadata_table_with_values` and `metadata_table_with_values` from the `metadata` module.   

    :param base_path: Base path where the repository data is stored.
    :param organism_name: Name of the organism.
    :param sbml_file: Path to the SBML file.
    :param chokepoint_file: Path to the chokepoint file.
    :param smarttable_file: Path to the Smarttable file.

    :return: DataFrame with the betweenness centrality values.
    :return: DataFrame with the node degrees.
    :return: DataFrame with the chokepoints.
    """

    metabolism_dir = os.path.join(base_path, 'organism', organism_name, 'metabolism')

    print(f'---------- 1. Processing SBML file ----------')
    process_sbml(base_path, organism_name, sbml_file)
    print(f'---------- 1. Finished ----------')

    print(f'---------- 2. Generating Ubiquitous compounds file ----------')
    ubiquitous_checker(base_path, organism_name)
    print(f'---------- 2. Finished ----------')

    print(f'---------- 3. Generating network SIF file ----------')
    generate_sif(base_path, organism_name)
    print(f'---------- 3. Finished ----------')

    print(f'---------- 4. Map proteins and reactions ----------')
    locus_reaction_dict = process_genes_smarttable(base_path, organism_name, smarttable_file)
    print(f'---------- 4. Finished ----------')

    print(f'---------- 5. Calculate Centrality ----------')
    graph, subgraph, reaction_centrality_dict, reaction_edges_dict = read_sif(base_path, organism_name)
    bc_dict = mapping_metabolism(locus_reaction_dict, reaction_centrality_dict)
    edge_dict = mapping_metabolism(locus_reaction_dict, reaction_edges_dict)
    print(f'---------- 5. Finished ----------')

    print(f'---------- 6. Obtaining Choke-points ----------')
    producing_set, consuming_set, both_set = process_chokepoint_ptools(base_path, organism_name, chokepoint_file)
    producing_chokepoint, consuming_chokepoint, both_chokepoint = mapping_chokepoints(locus_reaction_dict, producing_set, consuming_set, both_set)
    print(f'---------- 6. Finished ----------')

    print(f'---------- 7. Generating results files ----------')
    bcentrality_df = metadata.metadata_table_with_values(base_path, organism_name, bc_dict, "betweenness_centrality", metabolism_dir, 0)
    edges_df = metadata.metadata_table_with_values(base_path, organism_name, edge_dict, "edges", metabolism_dir, 0)
    producing_df = metadata.metadata_table_with_values(base_path, organism_name, producing_chokepoint, "producing_chokepoints", metabolism_dir, 'None')
    consuming_df = metadata.metadata_table_with_values(base_path, organism_name, consuming_chokepoint, "consuming_chokepoints", metabolism_dir, 'None')
    both_df = metadata.metadata_table_with_values(base_path, organism_name, both_chokepoint, "both_chokepoints", metabolism_dir, 'None')
    print(f'---------- 7. Finished ----------')

    return bcentrality_df, edges_df, producing_df, consuming_df, both_df